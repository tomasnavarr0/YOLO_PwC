{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import cv2\n","import albumentations as A\n","import numpy as np\n","import os\n","import shutil\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{},"source":["## Transfer Learning to a YOLO (you only look once) model for Object Recognition"]},{"cell_type":"markdown","metadata":{},"source":["### Step 1: Resize all images to correct format"]},{"cell_type":"markdown","metadata":{},"source":["1. We must have all images in the correct format. Always this images have to be in a square format. In this case they going to ve 640x640 "]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["FIRST_IMG_DIR = \"YOLO\"\n","\n","SIZE = (640, 640)\n","\n","os.makedirs(FIRST_IMG_DIR, exist_ok=True)\n","\n","def resize_image(image_path: str, target_size: tuple[int,int]) -> np.ndarray:\n","    image = cv2.imread(image_path)\n","    if image is not None:\n","        resized_image = cv2.resize(image, target_size)\n","        return resized_image\n","\n","\n","for filename in os.listdir(FIRST_IMG_DIR):\n","    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n","        img_path = os.path.join(FIRST_IMG_DIR, filename)\n","        resized_image = resize_image(img_path, SIZE)\n","\n","        if resized_image is not None:\n","            resized_image_path = os.path.join(FIRST_IMG_DIR, filename)\n","            cv2.imwrite(resized_image_path, resized_image)\n","            "]},{"cell_type":"markdown","metadata":{},"source":["### Step 2: Image Augmentation"]},{"cell_type":"markdown","metadata":{},"source":["The second step is to do data augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["IMAGES_DIR = r'dataset\\images'\n","LABELS_DIR = r'dataset\\labels'"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-29T13:56:42.163610Z","iopub.status.busy":"2024-06-29T13:56:42.163329Z","iopub.status.idle":"2024-06-29T13:57:33.045310Z","shell.execute_reply":"2024-06-29T13:57:33.044420Z","shell.execute_reply.started":"2024-06-29T13:56:42.163587Z"},"id":"ke9c_HFEWBeK","outputId":"a9f9ea8f-0a64-4579-be54-fdcc1a17bf9f","trusted":true},"outputs":[],"source":["\n","AUGMENTED_IMG_DIR = r'dataset/images_augmented'\n","AUGMENTED_LABELS_DIR = r'dataset/labels_augmented'\n","\n","os.makedirs(AUGMENTED_IMG_DIR, exist_ok=True)\n","os.makedirs(AUGMENTED_LABELS_DIR, exist_ok=True)\n","\n","def load_images_and_labels(images_dir: str, labels_dir: str) -> tuple[list, list]:\n","    images = []\n","    labels = []\n","    for filename in os.listdir(images_dir):\n","        if filename.endswith('.jpg') or filename.endswith('.png'):\n","            img_path = os.path.join(images_dir, filename)\n","            label_path = os.path.join(labels_dir, filename.replace('.jpg', '.txt').replace('.png', '.txt'))\n","            image = cv2.imread(img_path)\n","            if image is not None:\n","                images.append(image)\n","                with open(label_path, 'r') as f:\n","                    labels.append(f.read())\n","    return images, labels\n","\n","\n","def save_augmented_data(image, label: str, image_name: str, label_name: str) -> None:\n","    cv2.imwrite(os.path.join(AUGMENTED_IMG_DIR, image_name), image)\n","    with open(os.path.join(AUGMENTED_LABELS_DIR, label_name), 'w') as f:\n","        f.write(label)\n","\n","transform = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.RandomBrightnessContrast(p=0.2),\n","    A.Rotate(limit=10, p=0.5),\n","    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=10, p=0.5)\n","], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n","\n","\n","def augment_data(image: np.ndarray, label: str) -> tuple[np.ndarray, str]:\n","    boxes = []\n","    class_labels = []\n","    for line in label.split('\\n'):\n","        if line.strip() == '':\n","            continue\n","        parts = line.strip().split()\n","        class_labels.append(int(parts[0]))\n","        boxes.append([float(x) for x in parts[1:]])\n","\n","    bboxes = []\n","    for box in boxes:\n","        bboxes.append(box)\n","\n","    augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n","    aug_image = augmented['image']\n","    aug_bboxes = augmented['bboxes']\n","    aug_class_labels = augmented['class_labels']\n","\n","    aug_bboxes = [[max(0, min(1, coord)) for coord in bbox] for bbox in aug_bboxes]\n","\n","    aug_label = ''\n","    for bbox, cls in zip(aug_bboxes, aug_class_labels):\n","        aug_label += f\"{cls} \" + \" \".join(map(str, bbox)) + '\\n'\n","\n","    return aug_image, aug_label.strip()\n","\n","\n","images, labels = load_images_and_labels(IMAGES_DIR, LABELS_DIR)\n","\n","for i, (image, label) in enumerate(zip(images, labels)):\n","    for j in range(5): \n","        try:\n","            aug_image, aug_label = augment_data(image, label)\n","            image_name = f'aug_{i}_{j}.jpg'\n","            label_name = f'aug_{i}_{j}.txt'\n","            save_augmented_data(aug_image, aug_label, image_name, label_name, AUGMENTED_IMG_DIR, AUGMENTED_LABELS_DIR)\n","        except ValueError as e:\n","            print(f\"Error: {e}\")\n","            continue\n"]},{"cell_type":"markdown","metadata":{},"source":["### Step 3: Split in train and validation"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["\n","TRAING_IMG_DIR = 'dataset/train/images'\n","TRAING_LABELS_DIR = 'dataset/train/labels'\n","\n","VAL_IMG_DIR = 'dataset/val/images'\n","VAL_LABELS_DIR = 'dataset/val/labels'\n","\n","os.makedirs(TRAING_IMG_DIR, exist_ok=True)\n","os.makedirs(TRAING_LABELS_DIR, exist_ok=True)\n","os.makedirs(VAL_IMG_DIR, exist_ok=True)\n","os.makedirs(VAL_LABELS_DIR, exist_ok=True)\n","\n","images = [f for f in os.listdir(AUGMENTED_IMG_DIR) if f.endswith('.jpg') or f.endswith('.png')]\n","labels = [f.replace('.jpg', '.txt').replace('.png', '.txt') for f in images]\n","\n","train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n","\n","def move_files(file_list: list[str], source_dir: str, dest_dir: str) -> None:\n","    for file_name in file_list:\n","        shutil.move(os.path.join(source_dir, file_name), os.path.join(dest_dir, file_name))\n","\n","move_files(train_images, AUGMENTED_IMG_DIR, TRAING_IMG_DIR)\n","move_files(val_images, AUGMENTED_IMG_DIR, VAL_IMG_DIR)\n","move_files(train_labels, AUGMENTED_LABELS_DIR, TRAING_LABELS_DIR)\n","move_files(val_labels, AUGMENTED_LABELS_DIR, VAL_LABELS_DIR)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5275728,"sourceId":8788659,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
